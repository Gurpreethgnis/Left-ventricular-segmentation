import tensorflow as tf
import glob
import os
import time
import numpy as np
from LV_segmentation import util
from LV_segmentation import preprocessing
from LV_segmentation.dcgan import discriminator
from LV_segmentation.dcgan import generator
import cv2
import matplotlib
from matplotlib import pyplot as plt

def generateZ(batch_size):
    return np.random.normal(size=[batch_size, 7, 7, 512])


X = tf.placeholder(tf.float32, [None, 224, 224, 3])  # image
z = tf.placeholder(tf.float32, [None, 7, 7, 512])  # noise


####################################################################
# Hyper-parameters
learning_rate = 0.0001
training_epochs = 2000
batch_size = 15  # mini batch size

# Data set and path
trainval_ratio = 5
test_ratio = 1
####################################################################


####################################################################
# Model setup
D = discriminator()    # the instance under discriminator is made under D
G = generator()

Gz = G(z)
dx = D(X)
dg = D(Gz)
# sampler = G(z)

# Objective - loss function
g_loss=tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(dg), logits=tf.nn.sigmoid(dg)))
d_loss_real=tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(dx), logits=tf.nn.sigmoid(dx)))
d_loss_fake=tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(dg), logits=tf.nn.sigmoid(dg)))
d_loss = d_loss_real + d_loss_fake
# tf.add_to_collection(name='g_loss', value=tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(dg), logits=tf.nn.sigmoid(dg))))
# tf.add_to_collection(name='d_loss', value=tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(dx), logits=tf.nn.sigmoid(dx))))
# tf.add_to_collection(name='d_loss', value=tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(dg), logits=tf.nn.sigmoid(dg))))
# d_loss = tf.add_n(tf.get_collection('d_loss'), name='total_d_loss')
# g_loss = tf.add_n(tf.get_collection('g_loss'), name='total_g_loss')
# tvars = tf.trainable_variables()
d_vars=[var for var in D.variables if 'D' in var.name]
g_vars=[var for var in G.variables if 'G' in var.name]
# print(len(tvars))
print('d_vars:' ,len(d_vars))
print('g_vars:' ,len(g_vars))

with tf.variable_scope(tf.get_variable_scope(), reuse=False) as scope:
    d_opt = tf.train.AdamOptimizer(learning_rate).minimize(d_loss, var_list=d_vars)
    g_opt = tf.train.AdamOptimizer(learning_rate).minimize(g_loss, var_list=g_vars)
####################################################################


# start_time = time.time()
# Launch the graph in a session
with tf.Session() as sess:
    ####################################################################
    # Preprocessing
    DIR = 'data/train'
    SAVE_DIR = 'history/temp/2'

    filelist = glob.glob(os.path.join(DIR, '*.jpg'))
    save_filelist = [str(i) + '.jpg' for i in range(training_epochs)]
    images = preprocessing.decode_image(filelist)
    trainX, testX = util.data_set2(images, trainval_ratio, test_ratio)
    trainX = [trainX[i] for i in range(trainval_ratio)]
    trainX = np.concatenate(trainX, axis=0)
    ####################################################################


    ####################################################################
    # Initialization
    tf.global_variables_initializer().run()  # global initialize
    util.load_class(D.parameters, 'vgg16_weights.npz', sess)  # local initialize (conv5)
    util.load_class(G.parameters, 'vgg16_weights.npz', sess)
    ####################################################################


    ####################################################################
    # For tensorboard
    # announce element
    tf.summary.scalar('g_loss', g_loss)  # it will be stored in a buffer
    tf.summary.scalar('d_loss', d_loss)  # it will be stored in a buffer
    # added in dcgan
    # tf.summary.histogram(name + '_W', kernel)
    # tf.summary.histogram(name + '_b', biases)
    # tf.summary.histogram(name + '_relu', output)
    # images_for_tensorboard = generator(batch_size, z_dimensions)
    # tf.summary.image('Generated_images', images_for_tensorboard, 10)
    merged = tf.summary.merge_all()
    writer = tf.summary.FileWriter(SAVE_DIR, sess.graph)
    # writer.add_graph(sess.graph)
    ####################################################################


    for i in range(training_epochs):
        print('epoch: ', i)
        # print(len(trainX))
        # print(batch_size)
        training_batch = zip(range(0, len(trainX), batch_size),
                             range(batch_size, len(trainX) + 1, batch_size))  # list > dictionary ?
        # zip(range(start, end, interval))
        # 0     72
        # 72    144
        # ...
        # 528   600
        # print(training_batch)


        ####################################################################
        # Training
        for start, end in training_batch:

            # print(sess.run(D(X), feed_dict={X:trainX[start:end]}))
            print('d_loss: ', sess.run(d_loss,  feed_dict={X:trainX[start:end], z: generateZ(batch_size)}))
            print('g_loss: ', sess.run(g_loss, feed_dict={z: generateZ(batch_size)}))
            # print(sess.run(D(X), feed_dict={X: trainX[start:end], z: generateZ(batch_size)}))
            # print(sess.run(G.deconv5_2, feed_dict={z: generateZ(batch_size)}))

            sess.run(d_opt, feed_dict={X: trainX[start:end], z: generateZ(batch_size)})
            sess.run(g_opt, feed_dict={z: generateZ(batch_size)})
        ####################################################################


        ####################################################################
        # For tensorboard
        summary = sess.run(merged, feed_dict={X: trainX[0:batch_size], z: generateZ(batch_size)})
        writer.add_summary(summary, i)
        ####################################################################


        ####################################################################
        # Images save
        image = sess.run(Gz, feed_dict={z: generateZ(batch_size)})
        image_gray = cv2.cvtColor(image[0]*255, cv2.COLOR_BGR2GRAY)
        fn= os.path.join(SAVE_DIR, save_filelist[i])
        cv2.imwrite(filename=fn, img=image_gray)
        # plt.switch_backend('Qt5agg')
        # You may wish to save or plot the image generated
        # to see how it looks like
        # print(image.shape)
        # for k in range(batch_size):
        #     plt.subplot(2,5,k+1)
        #     plt.imshow(image[k,:,:,:])
        #     plt.show()
        ####################################################################


        ####################################################################
        # Save the weight
        if i%100 is 0:
            path = [SAVE_DIR + '/weight' + str(i) + '.npy']
            # util.save_weight(sess, path)
            saver = tf.train.Saver()
            saver.save(sess, path)
            print("Model is saved in file: %s" % path)
        ####################################################################


    print('training finished')
