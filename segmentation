import tensorflow as tf
import numpy as np



def normalization(input):
    with tf.variable_scope('preprocess') as scope:
        mean = tf.constant([60, 60, 60], dtype=tf.float32, shape=[1, 1, 1, 3], name='img_mean')
        norm = tf.constant([255, 255, 255], dtype=tf.float32, shape=[1, 1, 1, 3], name='img_mean')
        output = (input - mean) / norm
        return output

def generateZ(batch_size):
    return np.random.normal(size=[batch_size, 7, 7, 512])



class inference:
    def __init__(self):
        # self.input = input
        self.parameters_e = {}  # endocder parameters
        self.parameters_d = {}  # decoder parameters
        self.reuse = False

    def __call__(self, input):
        with tf.variable_scope('VAE', reuse=self.reuse):
            if(self.reuse):
                tf.get_variable_scope().reuse_variables()

            # Encoder
            with tf.variable_scope('encoder'):
                # self.norminput = normalization(input)
                # conv1
                # with tf.variable_scope('conv1'):
                # input : 224*224*3
                self.conv1_1 = self.convlayer('conv1_1', [3, 3, 3, 64], [64], input)            # 224*224*64
                self.conv1_2 = self.convlayer('conv1_2', [3, 3, 64, 64], [64], self.conv1_1)    # 224*224*64
                self.skip1 = self.skip_connection('short_skip1', input, self.conv1_2)
                self.pool1 = tf.nn.max_pool(value=self.skip1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool1')  # 112 112 64
                # conv2
                # with tf.variable_scope('conv2'):
                # input : 112*112*64
                self.conv2_1 = self.convlayer('conv2_1', [3, 3, 64, 128], [128], self.pool1)    # 112*112*128
                self.conv2_2 = self.convlayer('conv2_2', [3, 3, 128, 128], [128], self.conv2_1) # 112*112*128
                self.skip2 = self.skip_connection('short_skip2', self.pool1, self.conv2_2)
                self.pool2 = tf.nn.max_pool(value=self.skip2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool2')  # 56 56 128
                # conv3
                # with tf.variable_scope('conv3'):
                # input : 64*64*128
                self.conv3_1 = self.convlayer('conv3_1', [3, 3, 128, 256], [256], self.pool2)   # 56*56*256
                self.conv3_2 = self.convlayer('conv3_2', [3, 3, 256, 256], [256], self.conv3_1) # 56*56*256
                self.conv3_3 = self.convlayer('conv3_3', [3, 3, 256, 256], [256], self.conv3_2) # 56*56*256
                self.skip3 = self.skip_connection('short_skip3', self.pool2, self.conv3_3)
                self.pool3 = tf.nn.max_pool(value=self.skip3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool3')  # 28 28 256
                # conv4
                # with tf.variable_scope('conv4'):
                # input : 28*28*256
                self.conv4_1 = self.convlayer('conv4_1', [3, 3, 256, 512], [512], self.pool3)   # 28*28*512
                self.conv4_2 = self.convlayer('conv4_2', [3, 3, 512, 512], [512], self.conv4_1) # 28*28*512
                self.conv4_3 = self.convlayer('conv4_3', [3, 3, 512, 512], [512], self.conv4_2) # 28*28*512
                self.skip4 = self.skip_connection('short_skip4', self.pool3, self.conv4_3)
                self.pool4 = tf.nn.max_pool(value=self.skip4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool4')  # 14 14 512
                # conv5
                # with tf.variable_scope('conv5'):
                # input : 14*14*512
                self.conv5_1 = self.convlayer('conv5_1', [3, 3, 512, 512], [512], self.pool4)   # 14*14*512
                self.conv5_2 = self.convlayer('conv5_2', [3, 3, 512, 512], [512], self.conv5_1) # 14*14*512
                self.conv5_3 = self.convlayer('conv5_3', [3, 3, 512, 512], [512], self.conv5_2) # 14*14*512
                self.pool5 = tf.nn.max_pool(value=self.conv5_3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool5') # 7 7 512
                self.encoded = self.pool5
                # self.variables_en = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='encoder')

            # Decoder
            with tf.variable_scope('decoder'):
                # deconv1
                self.unpool5 = tf.image.resize_bilinear(self.encoded, [14, 14]) # 14*14*512
                self.deconv5_3 = self.deconvlayer('conv5_3', [3, 3, 512, 512], [512], self.unpool5, [tf.shape(input)[0], 14, 14, 512])
                self.deconv5_2 = self.deconvlayer('conv5_2', [3, 3, 512, 512], [512], self.deconv5_3, [tf.shape(input)[0], 14, 14, 512])
                self.deconv5_1 = self.deconvlayer('conv5_1', [3, 3, 512, 512], [512], self.deconv5_2, [tf.shape(input)[0], 14, 14, 512])
                self.skip5 = self.skip_connection('long_skip1', self.pool4, self.deconv5_1)
                # deconv2
                self.unpool4 = tf.image.resize_bilinear(self.skip5, [28, 28])   # 28*28*512
                self.deconv4_3 = self.deconvlayer('conv4_3', [3, 3, 512, 512], [512], self.unpool4, [tf.shape(input)[0], 28, 28, 512])
                self.deconv4_2 = self.deconvlayer('conv4_2', [3, 3, 512, 512], [512], self.deconv4_3, [tf.shape(input)[0], 28, 28, 512])
                self.deconv4_1 = self.deconvlayer('conv4_1', [3, 3, 256, 512], [256], self.deconv4_2, [tf.shape(input)[0], 28, 28, 256])
                self.skip6 = self.skip_connection('long_skip2', self.pool3, self.deconv4_1)
                # deconv3
                self.unpool3 = tf.image.resize_bilinear(self.skip6, [56, 56])   # 56*56*256
                self.deconv3_3 = self.deconvlayer('conv3_3', [3, 3, 256, 256], [256], self.unpool3, [tf.shape(input)[0], 56, 56, 256])
                self.deconv3_2 = self.deconvlayer('conv3_2', [3, 3, 256, 256], [256], self.deconv3_3, [tf.shape(input)[0], 56, 56, 256])
                self.deconv3_1 = self.deconvlayer('conv3_1', [3, 3, 128, 256], [128], self.deconv3_2, [tf.shape(input)[0], 56, 56, 128])
                self.skip7 = self.skip_connection('long_skip3', self.pool2, self.deconv3_1)
                # deconv4
                self.unpool2 = tf.image.resize_bilinear(self.skip7, [112, 112]) # 112*112*128
                self.deconv2_2 = self.deconvlayer('conv2_2', [3, 3, 128, 128], [128], self.unpool2, [tf.shape(input)[0], 112, 112, 128])
                self.deconv2_1 = self.deconvlayer('conv2_1', [3, 3, 64, 128], [64], self.deconv2_2, [tf.shape(input)[0], 112, 112, 64])
                self.skip8 = self.skip_connection('long_skip4', self.pool1, self.deconv2_1)
                # deconv5
                self.unpool1 = tf.image.resize_bilinear(self.skip8, [224, 224]) # 224*224*64
                self.deconv1_2 = self.deconvlayer('conv1_2', [3, 3, 64, 64], [64], self.unpool1, [tf.shape(input)[0], 224, 224, 64])
                self.deconv1_1 = self.deconvlayer('conv1_1', [3, 3, 3, 64], [3], self.deconv1_2, [tf.shape(input)[0], 224, 224, 3])
                self.decoded = self.deconv1_1

                self.output = tf.sigmoid(self.decoded, name= 'out')*255
                # self.output = self.tanh
                # self.variables_de = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='decoder')

            self.reuse = True
            self.variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='VAE')

            return self.output

    def skip_connection(self, name, residual, input):
        with tf.variable_scope(name) as scope:
            # <tf.Tensor 'Placeholder:0' shape=(?, 224, 224, 3) dtype=float32>
            sum = tf.concat([residual, input], axis=3)
            kernel = tf.get_variable(name='skip_connection', shape=[1, 1, sum.shape[3], input.shape[3]], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=1e-2))
            output = tf.nn.conv2d(sum, kernel, [1, 1, 1, 1], padding='SAME')
            return output

    def convlayer(self, name, kernel, bias, input):
        with tf.variable_scope(name) as scope:
            kernel = tf.get_variable(name='weights', shape=kernel, dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=1e-2))
            biases = tf.get_variable(name='biases', shape=bias, dtype=tf.float32, initializer=tf.constant_initializer(1.0))
            conv = tf.nn.conv2d(input, kernel, [1, 1, 1, 1], padding='SAME')
            out = tf.nn.bias_add(conv, biases)
            # self.parameters = [kernel, biases]
            self.parameters_e[name+'_W'] = kernel
            self.parameters_e[name+'_b'] = biases
            # output = tf.nn.relu(out)
            output = tf.contrib.layers.batch_norm(tf.nn.relu(out), epsilon=1e-5)

            # for tensorboard
            tf.summary.histogram(name+'_W', kernel)
            tf.summary.histogram(name+'_b', biases)
            tf.summary.histogram(name+'_relu', output)
            return output

    def deconvlayer(self, name, kernel, bias, input, outputshape):
        with tf.variable_scope(name) as scope:
            kernel = tf.get_variable(name='weights', shape=kernel, dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=1e-2))
            biases = tf.get_variable(name='biases', shape=bias, dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=1e-2))
            conv = tf.nn.conv2d_transpose(input, kernel, outputshape, [1, 1, 1, 1], padding='SAME')
            out = tf.nn.bias_add(conv, biases)
            self.parameters_d[name+'_W'] = kernel
            # self.parameters[name+'_b'] = biases
            output = tf.contrib.layers.batch_norm(tf.nn.relu(out), epsilon=1e-5)
            # output = leaky_relu(out)

            # for tensorboard
            tf.summary.histogram(name + '_W', kernel)
            tf.summary.histogram(name + '_b', biases)
            tf.summary.histogram(name + '_relu', output)
            return output




